# pages/Conversations.py

import streamlit as st
st.set_page_config(page_title="ğŸ’¬ Conversations", layout="wide")

import asyncio
import json
from common.types import Message, TextPart
from state.host_agent_service import FetchAppState, ListRemoteAgents
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from service.client.client import ConversationClient
from service.types import SendMessageRequest
from dotenv import load_dotenv

load_dotenv(override=True)

def orchestrate_servers(question: str, servers: list[str]) -> tuple[list[str], str]:
    """
    LLMì—ê²Œ plan ê³¼ prompt ë¥¼ ìì—°ì–´ë¡œ ë½‘ì•„ì˜¤ê²Œ í•œ ë’¤, 
    'PLAN:' ë¼ì¸ê³¼ 'PROMPT:' ë¼ì¸ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
    """
    # 1) Orchestratorì—ê²Œ ë¬»ê¸°
    prompt = (
        "ë‹¹ì‹ ì€ A2A Orchestratorì…ë‹ˆë‹¤.\n"
        "ì´ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ í˜¸ì¶œí•  ì„œë²„ ëª©ë¡(plan)ê³¼, "
        "ê·¸ ê³„íšì„ ì‚¬ìš©ìì—ê²Œ ìŠ¹ì¸ ìš”ì²­í•  ë©”ì‹œì§€(prompt)ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n\n"
        "PLAN: http://ì„œë²„1, http://ì„œë²„2\n"
        "PROMPT: ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìì—°ì–´ ìŠ¹ì¸ ìš”ì²­ ë¬¸ì¥\n\n"
        f"ì§ˆë¬¸: {question}\n"
        f"ì„œë²„ ëª©ë¡: {', '.join(servers)}\n"
    )
    raw = st.session_state.chat_llm.invoke([HumanMessage(content=prompt)]).content

    # 2) PLAN/PROMPT ë¼ì¸ íŒŒì‹±
    plan = []
    user_prompt = "ìŠ¹ì¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ì˜ˆ/ì•„ë‹ˆì˜¤)"
    for line in raw.splitlines():
        if line.upper().startswith("PLAN:"):
            # ì‰¼í‘œë¡œ ë¶„ë¦¬, ê³µë°± ì œê±°
            plan = [u.strip().rstrip("/") for u in line[len("PLAN:"):].split(",") if u.strip()]
        elif line.upper().startswith("PROMPT:"):
            user_prompt = line[len("PROMPT:"):].strip()

    # ë””ë²„ê·¸
    st.text(f"â–¶ Orchestrator raw:\n{raw}")
    st.text(f"â–¶ Parsed plan: {plan}")
    st.text(f"â–¶ Parsed prompt: {user_prompt}")

    return plan, user_prompt

# â”€â”€ ì„¸ì…˜ ìŠ¤í† ì–´ ì´ˆê¸°í™” â”€â”€
if "chat_llm" not in st.session_state:
    st.session_state.chat_llm = ChatOpenAI(model="gpt-4o", temperature=0.0)
if "histories" not in st.session_state:
    st.session_state.histories = {}
if "current_conv" not in st.session_state:
    st.session_state.current_conv = None
# ìŠ¹ì¸ ëŒ€ê¸° ìƒíƒœ ì €ì¥
if "pending_plan" not in st.session_state:
    st.session_state.pending_plan = None
if "pending_input" not in st.session_state:
    st.session_state.pending_input = None

@st.cache_data(show_spinner=False)
def load_conversation_state(conv_id: str):
    return asyncio.run(FetchAppState(conv_id))


def main():
    st.title("ğŸ’¬ Agent-to-Agent Chat")

    # â”€â”€ ì‚¬ì´ë“œë°”: ì„¸ì…˜ ëª©ë¡ & ì„ íƒ â”€â”€
    with st.sidebar:
        st.header("ì„¸ì…˜ ëª©ë¡")
        if st.button("â• ìƒˆ ëŒ€í™”"):
            new_id = f"conv_{len(st.session_state.histories)+1}"
            st.session_state.histories[new_id] = []
            st.session_state.current_conv = new_id

        for cid in st.session_state.histories:
            if cid == st.session_state.current_conv:
                st.button(cid, disabled=True, use_container_width=True)
            else:
                if st.button(cid, key=f"btn_{cid}", use_container_width=True):
                    st.session_state.current_conv = cid

    conv_id = st.session_state.current_conv
    if not conv_id:
        st.error("â— ì„¸ì…˜ì„ ì„ íƒí•˜ê±°ë‚˜ â€˜ìƒˆ ëŒ€í™”â€™ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        return

    # â”€â”€ íˆìŠ¤í† ë¦¬ ë¡œë“œ & ë Œë”ë§ â”€â”€
    history = st.session_state.histories.setdefault(conv_id, [])
    if not history:
        state = load_conversation_state(conv_id)
        for m in state.messages:
            txt = "".join(p for p, mime in m.content if mime=="text/plain")
            history.append({"role": m.role, "content": txt})
    for e in history:
        av = "ğŸ§‘â€ğŸ’»" if e["role"]=="user" else "ğŸ¤–"
        with st.chat_message(e["role"], avatar=av):
            st.markdown(e["content"])

    # â”€â”€ ì‚¬ìš©ì ì…ë ¥ â”€â”€
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”â€¦")
    if not user_input:
        return

    # â”€â”€ (2ë‹¨ê³„) ìŠ¹ì¸ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘? â”€â”€
    if st.session_state.pending_plan is not None:
        # ìœ ì €ê°€ â€œì˜ˆ/ì•„ë‹ˆì˜¤â€ ëŒ€ë‹µ
        history.append({"role":"user","content":user_input})
        st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(user_input)

        plan = st.session_state.pending_plan
        original = st.session_state.pending_input

        if "ì˜ˆ" in user_input or "yes" in user_input.lower():
            # â”€â”€ ìŠ¹ì¸ í›„, plan ëŒ€ë¡œ ì—ì´ì „íŠ¸ í˜¸ì¶œ â”€â”€
            for addr in plan:
                try:
                    # 1) â€œTool: A2A@{addr}â€ í‘œì‹œ
                    st.chat_message("assistant", avatar="ğŸ¤–").markdown(f"ğŸ’¡ Tool: A2A@{addr}")

                    # 2) Message ìƒì„± ì‹œ metadataì— agent_url ì¶”ê°€
                    msg = Message(
                        role="user",
                        parts=[TextPart(text=st.session_state.pending_input)],
                        metadata={
                            "conversation_id": conv_id,
                            "agent_url": addr,          
                        }
                    )


                    resp = asyncio.run(SendMessage(msg))

                    # 4) ê²°ê³¼ í‘œì‹œ
                    result = getattr(resp, "result", "<No result>")
                    st.chat_message("assistant", avatar="ğŸ¤–").markdown(result)
                    history.append({"role": "assistant", "content": result})

                except Exception as e:
                    st.error(f"â›” {addr} ì—°ê²° ì‹¤íŒ¨: {e}")

        else:
            # â”€â”€ ê±°ë¶€: ê¸°ë³¸ LLM ì²˜ë¦¬ â”€â”€
            fallback = st.session_state.chat_llm.invoke([HumanMessage(content=original)]).content
            st.chat_message("assistant", avatar="ğŸ¤–").markdown(fallback)
            history.append({"role":"assistant","content":fallback})

        # ìŠ¹ì¸ ì ˆì°¨ ì´ˆê¸°í™”
        st.session_state.pending_plan = None
        st.session_state.pending_input = None
        return

    # â”€â”€ (1ë‹¨ê³„) ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ â”€â”€
    history.append({"role":"user","content":user_input})
    st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(user_input)

    remotes = asyncio.run(ListRemoteAgents()) or []
    servers = [a.url.rstrip("/") for a in remotes if getattr(a,"url",None)]

    # ì²« í˜¸ì¶œ: plan & prompt ìƒì„±
    plan, prompt = orchestrate_servers(user_input, servers)
    st.chat_message("assistant", avatar="ğŸ¤–").markdown(prompt)
    history.append({"role":"assistant","content":prompt})

    # ëŒ€ê¸° ìƒíƒœ ì €ì¥ (ë‘ ë²ˆì§¸ ì…ë ¥ì„ ìŠ¹ì¸/ê±°ë¶€ë¡œ ì²˜ë¦¬)
    st.session_state.pending_plan = plan
    st.session_state.pending_input = user_input


if __name__ == "__main__":
    main()
